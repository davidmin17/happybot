import OpenAI from "openai";

// ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - í•´í”¼ë´‡ì˜ ì„±ê²© ì •ì˜
export const SYSTEM_PROMPT = `ë„ˆëŠ” "í•´í”¼"ë¼ëŠ” ì´ë¦„ì˜ ì¹œí•œ ì¹œêµ¬ì•¼.
í¸í•˜ê³  ì¹œê·¼í•œ ë§íˆ¬ë¡œ ëŒ€í™”í•˜ê³ , ì´ëª¨ì§€ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©í•´.
ë°˜ë§ì„ ì‚¬ìš©í•˜ë˜ ì¡´ì¤‘í•˜ëŠ” íƒœë„ë¥¼ ìœ ì§€í•´.
ì§ˆë¬¸ì— ì„±ì‹¤í•˜ê²Œ ë‹µë³€í•˜ë˜, ë„ˆë¬´ í˜•ì‹ì ì´ì§€ ì•Šê²Œ ëŒ€í™”í•´.
ìœ ë¨¸ ê°ê°ë„ ìˆê³ , ë•Œë¡œëŠ” ì¥ë‚œìŠ¤ëŸ½ê²Œ ëŒ€ë‹µí•  ìˆ˜ë„ ìˆì–´.`;

// OpenAI í´ë¼ì´ì–¸íŠ¸ (ì§€ì—° ì´ˆê¸°í™”)
let openaiClient: OpenAI | null = null;

function getOpenAIClient(): OpenAI {
  if (!openaiClient) {
    openaiClient = new OpenAI({
      baseURL: "https://models.github.ai/inference",
      apiKey: process.env.GITHUB_TOKEN,
    });
  }
  return openaiClient;
}

// ëŒ€í™” ë©”ì‹œì§€ íƒ€ì…
export interface ChatMessage {
  role: "system" | "user" | "assistant";
  content: string;
}

// AI ì‘ë‹µ ìƒì„± (ëŒ€í™” ê¸°ë¡ í¬í•¨)
export async function generateResponse(
  userMessage: string,
  conversationHistory: ChatMessage[] = []
): Promise<string> {
  try {
    const openai = getOpenAIClient();

    // ë©”ì‹œì§€ êµ¬ì„±: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ëŒ€í™” ê¸°ë¡ + í˜„ì¬ ë©”ì‹œì§€
    const messages: ChatMessage[] = [
      { role: "system", content: SYSTEM_PROMPT },
      ...conversationHistory,
      { role: "user", content: userMessage },
    ];

    const completion = await openai.chat.completions.create({
      model: "openai/gpt-5-mini",
      messages,
      max_tokens: 1000,
      temperature: 0.8,
    });

    return (
      completion.choices[0]?.message?.content ||
      "ì•—, ë­”ê°€ ë¬¸ì œê°€ ìƒê²¼ì–´! ë‹¤ì‹œ ë¬¼ì–´ë´ì¤„ë˜? ğŸ˜…"
    );
  } catch (error: unknown) {
    console.error("OpenAI API error:", error);

    // ì½˜í…ì¸  í•„í„° ì—ëŸ¬ ì²˜ë¦¬
    if (
      error instanceof Error &&
      "code" in error &&
      (error as { code?: string }).code === "content_filter"
    ) {
      return "ìŒ... ê·¸ ì§ˆë¬¸ì€ ì¢€ ë¯¼ê°í•œ ê²ƒ ê°™ì•„ì„œ ëŒ€ë‹µí•˜ê¸° ì–´ë ¤ì›Œ ğŸ˜… ë‹¤ë¥¸ ì–˜ê¸° í•˜ì!";
    }

    throw error;
  }
}
